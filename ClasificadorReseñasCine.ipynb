{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación reseñas de cine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, Conv1D, MaxPooling1D, Bidirectional\n",
    "from tensorflow.keras.datasets import imdb\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga dataset IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset IMDB. Las reseñas ya vienen tokenizadas.\n",
    "max_words = 5000  # Tamaño del vocabulario\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir longitud máxima de las secuencias\n",
    "max_len = 200\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=64, input_length=max_len), # Cada frase se convierte en una matriz de [200x64]\n",
    "    Conv1D(128, 5, activation='relu'),  # 128 filtros de tamaño 5 (analiza 5 palabras a la vez)\n",
    "    MaxPooling1D(pool_size=4), # Reduce la dimensionalidad seleccionando el valor máximo de cada grupo de 4 pasos\n",
    "    # LSTM con regularización más suave\n",
    "    Bidirectional(LSTM(64, return_sequences=False)), # return_sequences=False sólo devuelve la última salida\n",
    "    Dropout(0.2),  \n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', # función de pérdida usada en problemas de clasificación binaria\n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      " 5056/25000 [=====>........................] - ETA: 36s - loss: 0.5676 - accuracy: 0.6671"
     ]
    }
   ],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', restore_best_weights=True, patience=5)\n",
    "# Entrenar el modelo (puedes ajustar el número de épocas según sea necesario)\n",
    "epochs = 10\n",
    "history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), verbose=1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la pérdida y precisión\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Pérdida del Modelo\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Precisión del Modelo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizador. El dataset de IMDB ya trae el contenido tokenizado así que tenemos que cargar el mismo Tokenizador usado por IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el índice de palabras del dataset IMDB\n",
    "word_index = imdb.get_word_index()\n",
    "# Crear el tokenizador con el mismo vocabulario\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.word_index = {k: (v + 3) for k, v in word_index.items()}  # Ajuste de índices\n",
    "tokenizer.word_index[\"<PAD>\"] = 0\n",
    "tokenizer.word_index[\"<START>\"] = 1\n",
    "tokenizer.word_index[\"<UNK>\"] = 2  # Desconocidas\n",
    "tokenizer.word_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función clasificadora de reseñas positivas (1) y negativas (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_anomalia(texto):\n",
    "    seq = tokenizer.texts_to_sequences([texto])\n",
    "    seq_padded = pad_sequences(seq, maxlen=max_len, padding='post')\n",
    "    prediccion = model.predict(seq_padded)[0,0]\n",
    "    \n",
    "    print(f\"Texto: {texto}\\nProbabilidad de anomalía: {prediccion:.4f}\")\n",
    "    if prediccion > 0.5:\n",
    "        print(\"¡Anomalía detectada!\\n\")\n",
    "    else:\n",
    "        print(\"Texto normal.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reseñas a clasificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reseñas_positivas_ingles = [\n",
    "    \"Amazing movie, the acting is brilliant and the story very emotional. It kept me hooked from beginning to end. I would definitely watch it again.\",\n",
    "    \"A masterpiece. The special effects are impressive and the soundtrack is perfect. I totally recommend it to anyone who loves cinema.\",\n",
    "    \"I loved every moment, a well-told story and endearing characters. Great development and an epic ending that left me speechless.\",\n",
    "    \"Funny, exciting and with a great message. The chemistry between the actors is excellent, and the script is full of memorable moments.\",\n",
    "    \"Perfect combination of action and drama. I was pleasantly surprised, I expected less but it turned out to be one of the best movies I've seen.\"\n",
    "]\n",
    "\n",
    "reseñas_negativas_ingles = [\n",
    "    \"Terrible. The script is boring, the characters flat and the plot makes no sense. It was hard for me to finish it, a big disappointment.\",\n",
    "    \"The worst movie of the year. Bad acting, poor visual effects and a predictable plot. I don't understand how people enjoy it.\",\n",
    "    \"Nothing remarkable, full of clichés and unnecessary moments. I wasted two hours of my life on this. I don't recommend it at all.\",\n",
    "    \"It tried to be deep but failed. Slow development and an absurd ending. I really expected something better, but it left me with a feeling of emptiness.\",\n",
    "    \"I don't understand the good reviews. I found it forced and soulless. Not even the actors could save it. A waste of time and money.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación de reseñas Positivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res_positiva in reseñas_positivas_ingles:\n",
    "    detectar_anomalia(res_positiva)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación de reseñas Negativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res_negativa in reseñas_negativas_ingles:\n",
    "    detectar_anomalia(res_negativa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
